{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "v1.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daudcanugerah/prototype/blob/master/v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weQoT5AaABue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install  tensorflow==2.0 scikit-learn emoji matplotlib tensorboard==2.0.0 tensorflow_hub seaborn numpy pandas symspellpy\n",
        "!pip install git+git://github.com/snowballstem/pystemmer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qggsvE3iAEUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "try:\n",
        "  # Use the %tensorflow_version magic if in colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import string\n",
        "from google.colab import drive\n",
        "import re\n",
        "from sklearn import model_selection, metrics\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from datetime import datetime\n",
        "import emoji\n",
        "import json\n",
        "import io\n",
        "import Stemmer\n",
        "import itertools\n",
        "import os\n",
        "from itertools import zip_longest\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVmPyy-kARdA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "now = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "main_dir = 'drive/My Drive/sentiment/'\n",
        "log_dir = main_dir+'logs/model/'+now\n",
        "stemmer = Stemmer.Stemmer('indonesian')\n",
        "text_writer = tf.summary.create_file_writer(\n",
        "    main_dir+\"logs/text/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQ5bZjPcAnCj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trasform_sentiment(x):\n",
        "    if(x == -1):\n",
        "        return 0\n",
        "    elif(x == 1):\n",
        "        return 2\n",
        "    else:\n",
        "      return 1\n",
        " \n",
        "def custom_stemmer(text):\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    text = ''.join(i for i in text if not i.isdigit())\n",
        "    text = re.sub(r'(#|@)\\w+', '', text)\n",
        "    for char in list('\"!#$%&\\'()*+,-./:;<=>@[\\\\]^_`{|}~'):\n",
        "        text = text.replace(char, ' ')\n",
        "    text =  emoji.demojize(text)\n",
        "    text =  re.sub(r'((?=:(.*):)(?=:(.*):))', ' ',text)\n",
        "    text =  re.sub(r'([\\?])', r' \\1',text)\n",
        "    text = re.sub(\":\",'',text)    \n",
        "    text = text.lower().strip()\n",
        "    text = re.sub(\"\\s\\s+\", \" \", text)\n",
        "    return text\n",
        "\n",
        "def transform_predection_writer(x_test, y_tesx, y_prediction):\n",
        "    fp = [['***Text***','***Predict***','***Real***']]\n",
        "    fn = []\n",
        "    for num, text in enumerate(x_test):\n",
        "        if(y_test[num] == 0 and y_prediction[num].numpy() != 0):\n",
        "            fn.append([text,str(y_prediction[num].numpy()),str(y_test[num])])\n",
        "        elif(y_test[num] == 1 and y_prediction[num].numpy() != 1):\n",
        "            fn.append([text,str(y_prediction[num].numpy()),str(y_test[num])])\n",
        "    return fp,fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnsV2b5SAohG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datasets = pd.read_json(main_dir+'datasets/data_training.json')\n",
        "# print('filter by category')\n",
        "datasets = datasets[datasets['category'] == 'telco']\n",
        "# print('filter by sentiment')\n",
        "print('transform sentiment')\n",
        "datasets['sentiment'] = datasets['sentiment'].apply(trasform_sentiment)\n",
        "print('custom stimmer')\n",
        "datasets['text'] = datasets['text'].apply(custom_stemmer)\n",
        "print('drop na')\n",
        "datasets.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwF2K7j5AqMl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = datasets['text'].values\n",
        "Y = datasets['sentiment'].values\n",
        "\n",
        "x_train, x_test, y_train, y_test = model_selection.train_test_split(\n",
        "    X, Y, test_size=0.3)\n",
        "x_train, x_eval, y_train, y_eval = model_selection.train_test_split(\n",
        "    x_train, y_train, test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWFFlbncAsRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hub_layer = hub.KerasLayer(\n",
        "        \"https://tfhub.dev/google/nnlm-id-dim128-with-normalization/2\", input_shape=[], dtype=tf.string, trainable=True)\n",
        "model = Sequential()\n",
        "model.add(hub_layer)\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(16, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(16, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(3, activation='softmax'))\n",
        "# load weight\n",
        "model.load_weights(main_dir+\"checkpoint/weights.best.loss.hdf5\")\n",
        "# sgd = tf.keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-62AR0vAuAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=100,\n",
        "    verbose=1,\n",
        "    validation_data=[x_test, y_test],\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.TensorBoard(log_dir=log_dir),\n",
        "        tf.keras.callbacks.ModelCheckpoint(main_dir+\"checkpoint/weights.best.loss.hdf5\", monitor='val_loss', verbose=1, save_best_only=True, mode='auto'),\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_loss')\n",
        "    ]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKrrvvbxD-mK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate(\n",
        "    x_eval,\n",
        "    y_eval,\n",
        "    verbose=2,\n",
        "    batch_size=64,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irDpzo4TIBgu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = model.predict(x_test)\n",
        "y_prediction = tf.argmax(prediction, 1)\n",
        "matrix_confusion = metrics.confusion_matrix(y_test, y_prediction)\n",
        "report = metrics.classification_report(y_test, y_prediction)\n",
        "print(report)\n",
        "\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.title('Confusion Matrix')\n",
        "matrix_confusion = pd.DataFrame(matrix_confusion,index=['negative','neutral', 'positive'],columns=['negative','neutral', 'positive'])\n",
        "sns.heatmap(matrix_confusion, annot=True, fmt=\"d\", cbar=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twOp9hUBIKIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# save model\n",
        "model.save(main_dir+'model/model-3label-v1.h5')\n",
        "# with open('model/model-tfidf-'+category+'-'+now+'.pkl', 'wb') as f:\n",
        "#     tfidf = pickle.dump(vectorizer, f)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OfSVuZZKVoE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gm4COE5-KV8G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(metrics.classification_report(y_test, y_prediction, target_names=['negative','neutral', 'positive']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLpp7G1ozWnO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import files\n",
        "df = pd.DataFrame({'text':x_test,'real':y_test,'predict':y_prediction.numpy()})\n",
        "# files.download('df.csv')\n",
        "# save heatmap"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONZ3S7lN1TAi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}